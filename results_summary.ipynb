{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Summary - Code Comment Classification\n",
    "\n",
    "This notebook summarizes the complete pipeline results and provides conclusions.\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "1. **Data Cleaning** (`data_cleaning.ipynb`)\n",
    "   - Loaded 12,775 rows from original dataset\n",
    "   - BERT similarity analysis identified most confusable categories\n",
    "   - Automatically merged Usage → DevelopmentNotes (similarity: 0.9249)\n",
    "   - Filtered to 2,812 labeled samples (4 categories)\n",
    "   - Split into train (2,249) and test (563)\n",
    "\n",
    "2. **Feature Encoding** (`encoding.ipynb`)\n",
    "   - BERT embeddings: 384 features\n",
    "   - Class one-hot encoding: 306 features\n",
    "   - Metadata features: 5 features\n",
    "   - **Total: 695 features**\n",
    "\n",
    "3. **Baseline Model** (`model_training.ipynb`)\n",
    "   - GridSearchCV with Logistic Regression\n",
    "   - Best CV F1-Macro: 0.672\n",
    "   - Test Accuracy: 69.4%\n",
    "\n",
    "4. **Multi-Model Comparison** (`multi_model_training.ipynb`)\n",
    "   - Tested 4 algorithms\n",
    "   - Logistic Regression: 0.6704 (best)\n",
    "   - Linear SVC: 0.6608\n",
    "   - SGD Classifier: 0.6406\n",
    "   - Random Forest: 0.4984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Key Findings\n",
    "\n",
    "### Final Model Performance\n",
    "\n",
    "This notebook implements an **automatic category merging** approach based on BERT similarity analysis combined with BERT embeddings and metadata features for classification.\n",
    "\n",
    "**Best Model:** Logistic Regression with RandomOverSampler\n",
    "- **Test Accuracy: 69.4%**\n",
    "- **F1-Macro Score: 0.67**\n",
    "- **Cross-Validation F1-Macro: 0.672**\n",
    "\n",
    "### Per-Category Performance\n",
    "\n",
    "**Strong Categories:**\n",
    "- **Parameters (Class 2):** F1=0.77 ✓ - Clear vocabulary (parameter-related keywords)\n",
    "- **DevelopmentNotes (Class 0):** F1=0.74 ✓ - Largest class after merge, well-defined\n",
    "\n",
    "**Moderate Categories:**\n",
    "- **Summary (Class 3):** F1=0.65 - Good recall (0.69) but lower precision (0.61)\n",
    "\n",
    "**Struggling Categories:**\n",
    "- **Expand (Class 1):** F1=0.52 ❌ - Lowest performance, confusion with other classes\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "Tested 4 different algorithms (all with RandomOverSampler):\n",
    "\n",
    "| Model | Mean F1-Macro | Std Dev | Winner |\n",
    "|-------|---------------|---------|--------|\n",
    "| Logistic Regression | 0.6704 | 0.033 | ✓ Best |\n",
    "| Linear SVC | 0.6608 | 0.034 | |\n",
    "| SGD Classifier | 0.6406 | 0.034 | |\n",
    "| Random Forest | 0.4984 | 0.018 | ❌ Worst |\n",
    "\n",
    "Linear models (Logistic Regression, SVC) significantly outperform Random Forest when using dense BERT embeddings.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This pipeline successfully demonstrates:\n",
    "- **Automatic category merging** based on semantic similarity analysis\n",
    "- **BERT embeddings + metadata** achieve 69.4% accuracy (F1-Macro: 0.67)\n",
    "- **Logistic Regression** outperforms complex models on this task\n",
    "- **Proper data handling** prevents leakage and ensures fair evaluation\n",
    "\n",
    "The 69.4% accuracy represents solid performance given:\n",
    "- Only 2,812 samples (small dataset)\n",
    "- Average 6.9 words per comment (limited context)\n",
    "- 4 categories with fuzzy semantic boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Files\n",
    "\n",
    "### Data Files:\n",
    "- `code-comment-classification-cleaned.csv` - Cleaned dataset (2,812 rows)\n",
    "- `code-comment-classification-train-unbalanced.csv` - Training set (2,249 rows)\n",
    "- `code-comment-classification-test.csv` - Test set (563 rows)\n",
    "\n",
    "### Encoded Features:\n",
    "- `train_features_4cat_bert_meta.npz` - Training features (2,249 × 695)\n",
    "- `test_features_4cat_bert_meta.npz` - Test features (563 × 695)\n",
    "- `train_target_4cat_meta.csv` - Training labels\n",
    "- `test_target_4cat_meta.csv` - Test labels\n",
    "\n",
    "### Encoders:\n",
    "- `class_encoder_4cat_meta.pkl` - OneHotEncoder for class names\n",
    "- `bert_model_4cat_meta.pkl` - SentenceTransformer model\n",
    "- `label_encoder_4cat_meta.pkl` - LabelEncoder for categories\n",
    "\n",
    "### Trained Models:\n",
    "- `best_model_final.pkl` - Best performing model (Logistic Regression)\n",
    "\n",
    "## How to Use\n",
    "\n",
    "### Run the complete pipeline:\n",
    "```bash\n",
    "# 1. Clean data and merge categories\n",
    "jupyter notebook data_cleaning.ipynb\n",
    "\n",
    "# 2. Encode features\n",
    "jupyter notebook encoding.ipynb\n",
    "\n",
    "# 3. Train baseline model\n",
    "jupyter notebook model_training.ipynb\n",
    "\n",
    "# 4. Compare multiple models\n",
    "jupyter notebook multi_model_training.ipynb\n",
    "\n",
    "# 5. View results summary\n",
    "jupyter notebook results_summary.ipynb\n",
    "```\n",
    "\n",
    "### Load and use the trained model:\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Load model\n",
    "model = joblib.load(\"best_model_final.pkl\")\n",
    "\n",
    "# Load encoders\n",
    "class_encoder = joblib.load(\"class_encoder_4cat_meta.pkl\")\n",
    "bert_model = joblib.load(\"bert_model_4cat_meta.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder_4cat_meta.pkl\")\n",
    "\n",
    "# Make predictions on new data\n",
    "# (after encoding features the same way)\n",
    "predictions = model.predict(X_new)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}