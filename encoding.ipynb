{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9252616e",
   "metadata": {},
   "source": [
    "# Code Comment Classification - Encoding\n",
    "\n",
    "This notebook performs the following encoding operations:\n",
    "1. Load the cleaned dataset\n",
    "2. Select features and target\n",
    "3. Build a prepocessing pipeline\n",
    "4. Apply the transformations to encode the dataset\n",
    "5. Convert the sparse matrix to a dataframe \n",
    "6. Save the final encoded dataset and the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30db72",
   "metadata": {},
   "source": [
    "## 1. Load the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file containing your cleaned dataset\n",
    "df = pd.read_csv(\"code-comment-classification-cleaned.csv\")\n",
    "\n",
    "# Show the first few rows to confirm it loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2250558",
   "metadata": {},
   "source": [
    "## 2. Select features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the columns we will use as inputs for the model.\n",
    "# They contain:\n",
    "#   - categorical data: class, category\n",
    "#   - text data: comment_sentence\n",
    "#   - numeric data: partition\n",
    "FEATURES = [\"class\", \"category\", \"comment_sentence\", \"partition\"]\n",
    "\n",
    "# This is the value we want to predict (binary classification)\n",
    "TARGET = \"instance_type\"\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b8517",
   "metadata": {},
   "source": [
    "## 3. Build a prepocessing pipeline\n",
    "We use ColumnTransformer to apply different preprocessing steps\n",
    "to different columns:\n",
    "- `OneHotEncoder` for categorical columns\n",
    "- `TfidfVectorizer` for the text column\n",
    "- passthrough for numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233892ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Encode categorical columns into one-hot vectors\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"class\", \"category\"]),\n",
    "\n",
    "        # Convert comment_sentence text into TF-IDF features\n",
    "        (\"text\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2)), \n",
    "         \"comment_sentence\"),\n",
    "\n",
    "        # Keep numerical columns as they are\n",
    "        (\"num\", \"passthrough\", [\"partition\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessing pipeline on the dataset\n",
    "# (This learns the vocabulary for TF-IDF and unique categories)\n",
    "preprocess.fit(X)\n",
    "\n",
    "print(\"Preprocessing pipeline fitted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8d184",
   "metadata": {},
   "source": [
    "## 4. Apply the transformations to encode the dataset\n",
    "This produces a sparse matrix containing:\n",
    "- one-hot encoded categorical features\n",
    "- TF-IDF encoded text features\n",
    "- numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7de13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = preprocess.transform(X)\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c53d43",
   "metadata": {},
   "source": [
    "## 5. Convert the sparse matrix to a dataframe\n",
    "This is only for demonstrating the final encoded output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be381a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Retrieve the names of the generated features for interpretability\n",
    "cat_features = preprocess.named_transformers_[\"cat\"].get_feature_names_out(\n",
    "    [\"class\", \"category\"]\n",
    ")\n",
    "text_features = preprocess.named_transformers_[\"text\"].get_feature_names_out()\n",
    "num_features = [\"partition\"]\n",
    "\n",
    "# Combine them in order\n",
    "all_feature_names = list(cat_features) + list(text_features) + num_features\n",
    "\n",
    "# Convert sparse matrix to dense numpy array\n",
    "X_dense = X_encoded.toarray()\n",
    "\n",
    "# Create a DataFrame for inspection\n",
    "encoded_df = pd.DataFrame(X_dense, columns=all_feature_names)\n",
    "\n",
    "# Add the target column for completeness\n",
    "encoded_df[\"target\"] = y.values\n",
    "\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c2066",
   "metadata": {},
   "source": [
    "## 6. Save the final encoded dataset and the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ec8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "# Save encoded feature matrix in sparse format (.npz)\n",
    "sparse.save_npz(\"encoded_features.npz\", csr_matrix(X_encoded))\n",
    "\n",
    "# Save target values\n",
    "y.to_csv(\"target.csv\", index=False)\n",
    "\n",
    "# Save the preprocessing pipeline so we can use it later\n",
    "joblib.dump(preprocess, \"preprocessing_pipeline.pkl\")\n",
    "\n",
    "print(\"Files saved:\")\n",
    "print(\"- encoded_features.npz\")\n",
    "print(\"- target.csv\")\n",
    "print(\"- preprocessing_pipeline.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
