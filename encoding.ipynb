{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9252616e",
   "metadata": {},
   "source": [
    "# Code Comment Classification - Encoding\n",
    "\n",
    "This notebook performs the following encoding operations:\n",
    "1. Load the split dataset\n",
    "2. Separate features and target\n",
    "3. Encode the Target Labels\n",
    "4. Build and Fit the Feature Engineering Pipeline\n",
    "5. Transform and Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30db72",
   "metadata": {},
   "source": [
    "## 1. Load the split datasets\n",
    "We load the separate Training and Testing files created in the previous cleaning step. This ensures our test set remains unseen during the fitting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12c4039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:44:19.735508Z",
     "start_time": "2025-12-09T16:44:19.713484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (2291, 4)\n",
      "Test Set Shape:     (573, 4)\n",
      "Columns: ['comment_sentence_id', 'class', 'comment_sentence', 'category']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training data (Use this to learn patterns/vocabulary)\n",
    "df_train = pd.read_csv(\"code-comment-classification-train-unbalanced.csv\")\n",
    "\n",
    "# Load the test data (Use this ONLY for evaluation)\n",
    "df_test = pd.read_csv(\"code-comment-classification-test.csv\")\n",
    "\n",
    "print(f\"Training Set Shape: {df_train.shape}\")\n",
    "print(f\"Test Set Shape:     {df_test.shape}\")\n",
    "\n",
    "# Verify columns\n",
    "print(\"Columns:\", df_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2250558",
   "metadata": {},
   "source": [
    "## 2. Separate features and target\n",
    "We separate the input features (`class`, `comment_sentence`) from the target variable (`category`) for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c19d29c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:44:19.768630Z",
     "start_time": "2025-12-09T16:44:19.764524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and Target separated.\n"
     ]
    }
   ],
   "source": [
    "FEATURES = [\"class\", \"comment_sentence\"]\n",
    "TARGET = \"category\"\n",
    "\n",
    "# Split Training Data\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[TARGET]\n",
    "\n",
    "# Split Test Data\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "print(\"Features and Target separated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589da5a",
   "metadata": {},
   "source": [
    "## 3. Encode the Target Labels\n",
    "We convert the text labels (e.g., \"Usage\", \"Summary\") into numbers (0, 1, 2...).\n",
    "- We `.fit()` the label encoder only on `y_train`\n",
    "- We check if the test set contains any new labels (unlikely in this dataset, but good practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629b8517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category to Numeric Mapping:\n",
      "  DevelopmentNotes: 0\n",
      "  Expand: 1\n",
      "  Parameters: 2\n",
      "  Summary: 3\n",
      "  Usage: 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on Training labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform Test labels (using the same mapping)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Category to Numeric Mapping:\")\n",
    "for i, category in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {category}: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f8d0f",
   "metadata": {},
   "source": [
    "## 4. Build and Fit the Feature Engineering Pipeline\n",
    "We build a pipeline to transform our raw data into numbers.\n",
    "1. `OneHotEncoder`: Converts the `class` column into binary columns.\n",
    "2. `TfidfVectorizer`: Converts the `comment_sentence` into a matrix of word importance scores.\n",
    "\n",
    "It's important to note that we use `preprocess.fit(X_train)` to learn the vocabulary only from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233892ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:44:21.745676Z",
     "start_time": "2025-12-09T16:44:19.812012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessing pipeline on Training Data...\n",
      "Pipeline fitted.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the transformers\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Categorical: One-Hot Encoding\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"class\"]),\n",
    "        \n",
    "        # Text: TF-IDF Encoding\n",
    "        # We limit features to top 5000 to keep the model manageable\n",
    "        (\"text\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=5000), \"comment_sentence\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FIT ONLY ON TRAINING DATA\n",
    "print(\"Fitting preprocessing pipeline on Training Data...\")\n",
    "preprocess.fit(X_train)\n",
    "print(\"Pipeline fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50222222",
   "metadata": {},
   "source": [
    "## 5. Transform and Save Data\n",
    "Now we transform both datasets into sparse matrices (numbers). Then we save them separately so the Model Training notebook can load them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be20e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Train Shape: (2291, 5306)\n",
      "Encoded Test Shape:  (573, 5306)\n",
      "\n",
      "Files Saved Successfully:\n",
      "- train_features.npz & code-comment-classification-train-target.csv\n",
      "- test_features.npz  & code-comment-classification-test-target.csv\n",
      "- preprocessing_pipeline.pkl\n",
      "- label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "# 1. Transform the Training Data\n",
    "X_train_encoded = preprocess.transform(X_train)\n",
    "\n",
    "# 2. Transform the Test Data (using the pipeline fitted on train)\n",
    "X_test_encoded = preprocess.transform(X_test)\n",
    "\n",
    "print(f\"Encoded Train Shape: {X_train_encoded.shape}\")\n",
    "print(f\"Encoded Test Shape:  {X_test_encoded.shape}\")\n",
    "\n",
    "# --- SAVING FILES ---\n",
    "\n",
    "# Save Features (Sparse Matrices)\n",
    "sparse.save_npz(\"train_features.npz\", X_train_encoded)\n",
    "sparse.save_npz(\"test_features.npz\", X_test_encoded)\n",
    "\n",
    "# Save Targets (CSVs)\n",
    "pd.DataFrame(y_train_encoded, columns=['category']).to_csv(\"code-comment-classification-train-target.csv\", index=False)\n",
    "pd.DataFrame(y_test_encoded, columns=['category']).to_csv(\"code-comment-classification-test-target.csv\", index=False)\n",
    "\n",
    "# Save the Pipeline and Encoder for later use\n",
    "joblib.dump(preprocess, \"preprocessing_pipeline.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"\\nFiles Saved Successfully:\")\n",
    "print(\"- train_features.npz & code-comment-classification-train-target.csv\")\n",
    "print(\"- test_features.npz  & code-comment-classification-test-target.csv\")\n",
    "print(\"- preprocessing_pipeline.pkl\")\n",
    "print(\"- label_encoder.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
