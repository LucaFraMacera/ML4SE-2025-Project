{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Training - Code Comment Classification\n",
    "\n",
    "This notebook trains a baseline Logistic Regression model with hyperparameter tuning.\n",
    "\n",
    "## Steps:\n",
    "1. Load encoded features\n",
    "2. Build pipeline with RandomOverSampler + Logistic Regression\n",
    "3. GridSearchCV for hyperparameter tuning\n",
    "4. Evaluate on test set\n",
    "\n",
    "## Input Files:\n",
    "- `train_features_4cat_bert_meta.npz`\n",
    "- `test_features_4cat_bert_meta.npz`\n",
    "- `train_target_4cat_meta.csv`\n",
    "- `test_target_4cat_meta.csv`\n",
    "\n",
    "## Output:\n",
    "- Best hyperparameters\n",
    "- Test set performance\n",
    "- Classification report"
   ],
   "id": "c1516ed9c573e1b1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ],
   "id": "74f086a5c15b781"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Utilities\n",
    "from scipy import sparse\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ],
   "id": "158f4d66d5bb3561"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Model Training (Baseline)\n",
    "---"
   ],
   "id": "c9111f8a3a76ae17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Preprocessed Data\n",
    "We load the **already encoded** sparse matrices created in the encoding step. \n",
    "\n",
    "This ensures we are using the exact training/testing split that prevents data leakage."
   ],
   "id": "fd1e5748c9df5a77"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (2249, 695)\n",
      "Test Data:     (563, 695)\n"
     ]
    }
   ],
   "source": [
    "# Load Features (Sparse Matrices)\n",
    "X_train_model = sparse.load_npz(\"train_features_4cat_bert_meta.npz\")\n",
    "X_test_model = sparse.load_npz(\"test_features_4cat_bert_meta.npz\")\n",
    "\n",
    "# Load Targets (CSVs)\n",
    "# use .values.ravel() to convert dataframe column to simple 1D array\n",
    "y_train_model = pd.read_csv(\"train_target_4cat_meta.csv\").values.ravel() \n",
    "y_test_model = pd.read_csv(\"test_target_4cat_meta.csv\").values.ravel()\n",
    "\n",
    "print(f\"Training Data: {X_train_model.shape}\")\n",
    "print(f\"Test Data:     {X_test_model.shape}\")"
   ],
   "id": "d8191297006c5b54"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build Balanced Pipeline\n",
    "We use `imbalanced-learn`'s pipeline.\n",
    "1. **RandomOverSampler:** This will run *inside* the Cross-Validation loop. It balances the training folds but leaves the validation folds unbalanced (honest validation).\n",
    "2. **Classifier:** Logistic Regression."
   ],
   "id": "438f12c0a78bcb66"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created with Internal Balancing.\n",
      "Total hyperparameter combinations to test: 96 = 96\n",
      "This will take longer but should find optimal settings!\n",
      "Note: Some combinations are invalid (e.g., lbfgs + l1) and will be skipped.\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "# Note: No TfidfVectorizer here because X_train is already vectorized!\n",
    "pipeline = ImbPipeline([\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('clf', LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# EXTENSIVE HYPERPARAMETER TUNING\n",
    "# Testing multiple regularization strengths, solvers, penalties, and class weights\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__solver': ['liblinear', 'lbfgs'],\n",
    "    'clf__penalty': ['l1', 'l2'],  # 2 penalties\n",
    "    'clf__class_weight': ['balanced', None]  # 2 options\n",
    "}\n",
    "\n",
    "print(\"Pipeline created with Internal Balancing.\")"
   ],
   "id": "1baf55921dfaf22a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train and Evaluate (with Cross-Validation)\n",
    "We use `GridSearchCV` to find the best parameters. The `ImbPipeline` ensures that for every fold of cross-validation, the model is trained on balanced data but validated on real, unbalanced data."
   ],
   "id": "5c16cda832fe6c0c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 522, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.50758867        nan 0.62172122 0.63043829 0.50758867        nan\n",
      " 0.62172122 0.63043829 0.66700246        nan 0.67214923 0.67043345\n",
      " 0.66700246        nan 0.67214923 0.67043345 0.62918506        nan\n",
      " 0.6650989  0.64936718 0.62918506        nan 0.6650989  0.64936718]\n",
      "  warnings.warn(\n",
      "c:\\Users\\lmacera\\Desktop\\CodeCommentClassification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "Best CV Score (F1 Macro): 0.6721492337913795\n",
      "\n",
      "=== FINAL TEST SET RESULTS ===\n",
      "Accuracy: 0.69449378330373\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       212\n",
      "           1       0.51      0.52      0.52       101\n",
      "           2       0.78      0.77      0.77       159\n",
      "           3       0.61      0.69      0.65        91\n",
      "\n",
      "    accuracy                           0.69       563\n",
      "   macro avg       0.67      0.68      0.67       563\n",
      "weighted avg       0.70      0.69      0.70       563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Run Grid Search\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train_model, y_train_model)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best CV Score (F1 Macro):\", grid.best_score_)\n",
    "\n",
    "# 2. Final Evaluation on the Locked Test Set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test_model)\n",
    "\n",
    "print(\"\\n=== FINAL TEST SET RESULTS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_model, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test_model, y_pred))"
   ],
   "id": "df4018f634c8368e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
