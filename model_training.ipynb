{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30655f3",
   "metadata": {},
   "source": [
    "# Code Comment Classification - Model Training\n",
    "\n",
    "This notebook performs the following model training operations:\n",
    "1. Load Preprocessed Data\n",
    "2. Build Balanced Pipeline\n",
    "3. Train and Evaluate (with Cross-Validation)\n",
    "4. Save the Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6c013",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data\n",
    "We load the **already encoded** sparse matrices created in the `encoding.ipynb` notebook. \n",
    "\n",
    "This ensures we are using the exact training/testing split that prevents data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a983fd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.342781Z",
     "start_time": "2025-12-09T16:45:48.324510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (2291, 5306)\n",
      "Test Data:     (573, 5306)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Load Features (Sparse Matrices)\n",
    "X_train = sparse.load_npz(\"train_features.npz\")\n",
    "X_test = sparse.load_npz(\"test_features.npz\")\n",
    "\n",
    "# Load Targets (CSVs)\n",
    "# use .values.ravel() to convert dataframe column to simple 1D array\n",
    "y_train = pd.read_csv(\"code-comment-classification-train-target.csv\").values.ravel() \n",
    "y_test = pd.read_csv(\"code-comment-classification-test-target.csv\").values.ravel()\n",
    "\n",
    "print(f\"Training Data: {X_train.shape}\")\n",
    "print(f\"Test Data:     {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426b932",
   "metadata": {},
   "source": [
    "## 2. Build Balanced Pipeline\n",
    "We use `imbalanced-learn`'s pipeline.\n",
    "1. **RandomOverSampler:** This will run *inside* the Cross-Validation loop. It balances the training folds but leaves the validation folds unbalanced (honest validation).\n",
    "2. **Classifier:** Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1afec7c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.379373Z",
     "start_time": "2025-12-09T16:45:48.374865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created with Internal Balancing.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline\n",
    "# Note: No TfidfVectorizer here because X_train is already vectorized!\n",
    "pipeline = ImbPipeline([\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Define Hyperparameters for GridSearch\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "print(\"Pipeline created with Internal Balancing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61161654",
   "metadata": {},
   "source": [
    "## 3. Train and Evaluate (with Cross-Validation)\n",
    "We use `GridSearchCV` to find the best parameters. The `ImbPipeline` ensures that for every fold of cross-validation, the model is trained on balanced data but validated on real, unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e976d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.424088Z",
     "start_time": "2025-12-09T16:45:48.416585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 1, 'clf__solver': 'lbfgs'}\n",
      "Best CV Score (F1 Macro): 0.5755785949661258\n",
      "\n",
      "=== FINAL TEST SET RESULTS ===\n",
      "Accuracy: 0.5968586387434555\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.45      0.39        62\n",
      "           1       0.46      0.46      0.46       101\n",
      "           2       0.79      0.77      0.78       159\n",
      "           3       0.57      0.54      0.55        91\n",
      "           4       0.63      0.61      0.62       160\n",
      "\n",
      "    accuracy                           0.60       573\n",
      "   macro avg       0.56      0.56      0.56       573\n",
      "weighted avg       0.61      0.60      0.60       573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Run Grid Search\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best CV Score (F1 Macro):\", grid.best_score_)\n",
    "\n",
    "# 2. Final Evaluation on the Locked Test Set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== FINAL TEST SET RESULTS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593a07f",
   "metadata": {},
   "source": [
    "## 4. Save the Baseline Model\n",
    "We save the trained Logistic Regression pipeline. This serves as our **baseline** performance. Any future complex model (like Random Forest or SVM) must beat the **F1-Macro score of 0.57** to be considered an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6aedd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to best_logistic_regression.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the entire pipeline (including the oversampler and classifier)\n",
    "model_filename = \"best_logistic_regression.pkl\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "\n",
    "print(f\"Model saved successfully to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
