{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30655f3",
   "metadata": {},
   "source": [
    "# Code Comment Classification - Model Training\n",
    "\n",
    "This notebook performs the following model training operations:\n",
    "1. Load cleaned dataset (no outliers)\n",
    "2. Select features and target\n",
    "3. Split data into train and test sets\n",
    "4. Build ML pipeline (preprocessing + model)\n",
    "5. Train model\n",
    "6. Evaluate performance\n",
    "7. Save final model (pipeline + classifier)\n",
    "8. Hyperparameter Tuning\n",
    "9. Evaluate best model on test set\n",
    "10. Save best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6c013",
   "metadata": {},
   "source": [
    "## 1. Load cleaned dataset (no outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a983fd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.342781Z",
     "start_time": "2025-12-09T16:45:48.324510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (2864, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_sentence_id</th>\n",
       "      <th>class</th>\n",
       "      <th>comment_sentence</th>\n",
       "      <th>category</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512</td>\n",
       "      <td>MigrationGraph</td>\n",
       "      <td>migrations files can be marked as replacing an...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513</td>\n",
       "      <td>MigrationGraph</td>\n",
       "      <td>this is to support the squash feature.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514</td>\n",
       "      <td>MigrationGraph</td>\n",
       "      <td>the graph handler isn t responsible</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>515</td>\n",
       "      <td>MigrationGraph</td>\n",
       "      <td>for these instead, the code to load them in he...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>MigrationGraph</td>\n",
       "      <td>migration files and if the replaced migrations...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_sentence_id           class  \\\n",
       "0                  512  MigrationGraph   \n",
       "1                  513  MigrationGraph   \n",
       "2                  514  MigrationGraph   \n",
       "3                  515  MigrationGraph   \n",
       "4                  516  MigrationGraph   \n",
       "\n",
       "                                    comment_sentence  category  outlier  \n",
       "0  migrations files can be marked as replacing an...         4        0  \n",
       "1             this is to support the squash feature.         4        0  \n",
       "2                the graph handler isn t responsible         4        0  \n",
       "3  for these instead, the code to load them in he...         4        0  \n",
       "4  migration files and if the replaced migrations...         4        0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv(\"code-comment-classification-cleaned-no-outliers.csv\")\n",
    "\n",
    "print(\"Cleaned dataset shape:\", df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426b932",
   "metadata": {},
   "source": [
    "## 2. Select features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1afec7c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.379373Z",
     "start_time": "2025-12-09T16:45:48.374865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same features as before\n",
    "FEATURES = [\"class\", \"comment_sentence\"]\n",
    "TARGET = \"category\"\n",
    "\n",
    "X = df_clean[FEATURES]\n",
    "y = df_clean[TARGET]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61161654",
   "metadata": {},
   "source": [
    "## 3. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e976d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.424088Z",
     "start_time": "2025-12-09T16:45:48.416585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (2291, 2)\n",
      "Test size: (573, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standard 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa7b6c",
   "metadata": {},
   "source": [
    "## 4. Build ML pipeline (preprocessing + model)\n",
    "This is the cleanest and most professional approach: the pipeline contains both the preprocessing and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f342fff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.515827Z",
     "start_time": "2025-12-09T16:45:48.510821Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocessing:\n",
    "# - One-hot encoding for categorical features\n",
    "# - TF-IDF for text\n",
    "# - passthrough numeric feature\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"class\"]),\n",
    "        (\"text\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2)), \"comment_sentence\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final ML pipeline\n",
    "model = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=400, n_jobs=-1))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69488a82",
   "metadata": {},
   "source": [
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c2de06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.700Z",
     "start_time": "2025-12-09T16:45:48.562968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf8db7",
   "metadata": {},
   "source": [
    "## 6. Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac6a3af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.737605Z",
     "start_time": "2025-12-09T16:45:48.707013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5863874345549738\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.16      0.22        62\n",
      "           1       0.52      0.40      0.45       101\n",
      "           2       0.70      0.81      0.75       159\n",
      "           3       0.56      0.49      0.52        91\n",
      "           4       0.56      0.71      0.63       160\n",
      "\n",
      "    accuracy                           0.59       573\n",
      "   macro avg       0.53      0.51      0.51       573\n",
      "weighted avg       0.57      0.59      0.57       573\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 10   2  12  13  25]\n",
      " [  3  40  17  14  27]\n",
      " [  1   5 128   4  21]\n",
      " [  5  12  14  45  15]\n",
      " [ 11  18  13   5 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed metrics\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452b956",
   "metadata": {},
   "source": [
    "## 7. Save final model (pipeline + classifier)\n",
    "This includes both:\n",
    "- the preprocessing pipeline\n",
    "- the classifier\n",
    "So you can directly call `.predict()` on raw new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ef3a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:48.804531Z",
     "start_time": "2025-12-09T16:45:48.781060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_model_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"final_model_pipeline.pkl\")\n",
    "\n",
    "print(\"Saved: final_model_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e03e15",
   "metadata": {},
   "source": [
    "## Why `Logistic Regression`Was Chosen First\n",
    "`Logistic Regression` is the standard baseline model for text classification.\n",
    "It is preferred as the first model because:\n",
    "\n",
    "### 1. It performs extremely well on high-dimensional sparse data\n",
    "Our encoding uses:\n",
    "- TF-IDF (possibly thousands of features)\n",
    "- One-Hot encoding\n",
    "`Logistic Regression` with linear decision boundaries and `L2` regularization is specifically optimized for this kind of dataset.\n",
    "This is why it is the default first model in:\n",
    "- NLP text classification papers\n",
    "- Spam detection\n",
    "- Sentiment classification\n",
    "- Document categorization\n",
    "And why libraries like `scikit-learn`, `spaCy`, `fast.ai` use it as a baseline.\n",
    "\n",
    "### 2. It trains very fast\n",
    "Good for iterative development, checking preprocessing pipelines, etc.\n",
    "\n",
    "### 3. It provides interpretable coefficients\n",
    "Important for academic and professional settings.\n",
    "\n",
    "### 4. It handles sparse data better than tree models\n",
    "Tree-based models (`RandomForest`, `XGBoost`) struggle with high-dimensional sparse `TF-IDF`.\n",
    "`Logistic Regression` thrives in this setup.\n",
    "\n",
    "### 5. It works well with imbalanced data after tuning\n",
    "But our dataset is extremely imbalanced:\n",
    "- Class `0` support: `1982`\n",
    "- Class `1` support: `573`\n",
    "And class `1` is very different semantically (in text), so `LR` did not correctly learn minority class boundaries yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb7641",
   "metadata": {},
   "source": [
    "## Why the `F1` for class `1` is so low?\n",
    "Our results:\n",
    "\n",
    "```bash\n",
    "Class 1 Precision: 0.17\n",
    "Class 1 Recall:    0.01\n",
    "F1:                0.03\n",
    "```\n",
    "\n",
    "This means the model is predicting almost everything as class `0`, which is typical when:\n",
    "1. The dataset is imbalanced: `76%` of our data is class `0`.\n",
    "2. `LogisticRegression` default parameters are not tuned. By default:\n",
    "    - It uses `C=1` (weak regularization)\n",
    "    - Does NOT adjust for class imbalance\n",
    "    - Does NOT weigh classes equally\n",
    "3. `TF-IDF` vocabulary is dominated by majority class tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33c3c8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "`Logistic Regression` was chosen correctly as a baseline,\n",
    "but now we need to tune it to learn minority class patterns.\n",
    "\n",
    "This is exactly what we do next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e2bbf",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n",
    "We will tune:\n",
    "Preprocessing (TF-IDF)\n",
    "- `max_features`\n",
    "- `ngram_range`\n",
    "- `min_df`\n",
    "\n",
    "Model (Logistic Regression)\n",
    "- `C (regularization strength)`\n",
    "- `class_weight`\n",
    "- `penalty`\n",
    "- `solver`\n",
    "\n",
    "We use `GridSearchCV` inside the pipeline so everything stays clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3914350e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:54.197929Z",
     "start_time": "2025-12-09T16:45:48.887953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'preprocess__text__max_df': 0.85, 'preprocess__text__min_df': 2, 'preprocess__text__ngram_range': (1, 2)}\n",
      "\n",
      "Best F1-macro score: 0.5772711903045793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Rebuild pipeline so GridSearch can tune TF-IDF + LR\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"class\"]),\n",
    "        (\"text\", TfidfVectorizer(stop_words=\"english\"), \"comment_sentence\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=400, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Parameter grid to search\n",
    "param_grid = {\n",
    "    # TF-IDF parameters\n",
    "    \"preprocess__text__ngram_range\": [(1,1), (1,2)],\n",
    "    \"preprocess__text__min_df\": [1, 2, 3],\n",
    "    \"preprocess__text__max_df\": [0.85, 1.0],\n",
    "    \n",
    "    # Logistic Regression parameters\n",
    "    \"clf__C\": [0.1, 1, 3, 5],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\"],\n",
    "}\n",
    "\n",
    "# Grid search: F1 is better for imbalanced data\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"\\nBest F1-macro score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f9fee",
   "metadata": {},
   "source": [
    "## 9. Evaluate best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5dd623b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:54.231768Z",
     "start_time": "2025-12-09T16:45:54.203438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6195462478184991\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.52      0.43        62\n",
      "           1       0.49      0.50      0.49       101\n",
      "           2       0.80      0.77      0.79       159\n",
      "           3       0.60      0.60      0.60        91\n",
      "           4       0.69      0.59      0.64       160\n",
      "\n",
      "    accuracy                           0.62       573\n",
      "   macro avg       0.59      0.60      0.59       573\n",
      "weighted avg       0.63      0.62      0.62       573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9f7c4",
   "metadata": {},
   "source": [
    "##Â 10. Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc65ee09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:45:54.373066Z",
     "start_time": "2025-12-09T16:45:54.348814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: best_logistic_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, \"best_logistic_regression_model.pkl\")\n",
    "\n",
    "print(\"Saved: best_logistic_regression_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
