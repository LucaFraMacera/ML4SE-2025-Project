{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665a4dcf",
   "metadata": {},
   "source": [
    "## Motivation for Using Multiple Models\n",
    "\n",
    "Initially, we tried `Logistic Regression` as a baseline model because it is:\n",
    "\n",
    "- Fast to train\n",
    "- Well-suited for high-dimensional sparse data (like `TF-IDF`)\n",
    "- Interpretable and widely used in text classification\n",
    "\n",
    "However, after evaluating `Logistic Regression`, we observed:\n",
    "\n",
    "- High overall accuracy (`~0.76`), but extremely low `F1` for the minority class (`0.03`)\n",
    "- The model predicted almost all examples as the majority class due to **class imbalance**\n",
    "- This makes it **unsuitable for our task**, where detecting the minority class (`instance_type=1`) is important\n",
    "\n",
    "### Therefore, we try multiple alternative models to improve performance:\n",
    "\n",
    "1. `LinearSVC`\n",
    "   - `Linear Support Vector Machine` is well-known for text classification  \n",
    "   - Handles high-dimensional sparse data efficiently  \n",
    "   - Works well with imbalanced classes using `class_weight='balanced'`\n",
    "\n",
    "2. `SGDClassifier` (`Hinge` / `Log`)\n",
    "   - Implements stochastic gradient descent for linear models  \n",
    "   - Can be faster than traditional linear models on large datasets  \n",
    "   - Supports `class_weight='balanced'` for imbalanced data\n",
    "\n",
    "3. `Decision Forest` (`RandomForest`)\n",
    "   - Ensemble of decision trees capturing non-linear relationships  \n",
    "   - Robust to noise and outliers  \n",
    "   - Handles categorical and numeric features without much preprocessing\n",
    "\n",
    "4. `Gradient Boosting` (`XGBoost` / `LightGBM`) \n",
    "   - Powerful ensemble models that can learn complex patterns  \n",
    "   - Include mechanisms to handle class imbalance (`scale_pos_weight` or `class_weight`)  \n",
    "   - Often outperform linear models on structured and text-derived features\n",
    "\n",
    "5. `Neural Network` (`MLPClassifier`)\n",
    "   - Can capture non-linear interactions between features  \n",
    "   - Flexible architecture for combining text embeddings (`TF-IDF`) with categorical/numeric features  \n",
    "\n",
    "### Key Goals\n",
    "\n",
    "- Improve detection of minority class (class `1`) without sacrificing too much overall accuracy  \n",
    "- Maximize `F1`-macro, which balances performance across both classes  \n",
    "- Compare models to select the best performing pipeline for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea5023",
   "metadata": {},
   "source": [
    "## 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed948657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504e6e9",
   "metadata": {},
   "source": [
    "## 1. Load cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6dc9545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (10220, 4)\n",
      "Test size: (2555, 4)\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.read_csv(\"code-comment-classification-cleaned-no-outliers.csv\")\n",
    "\n",
    "FEATURES = [\"class\", \"category\", \"comment_sentence\", \"partition\"]\n",
    "TARGET = \"instance_type\"\n",
    "\n",
    "X = df_clean[FEATURES]\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "# Train/test split (80/20 stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847c2ae",
   "metadata": {},
   "source": [
    "## 2. Define preprocessing pipeline\n",
    "One pipeline for all models:\n",
    "- `OneHotEncoder` for categorical features\n",
    "- `TF-IDF` for text\n",
    "- passthrough numeric feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6608c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"class\", \"category\"]),\n",
    "        (\"text\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2)), \"comment_sentence\"),\n",
    "        (\"num\", \"passthrough\", [\"partition\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783828a5",
   "metadata": {},
   "source": [
    "## 3. Define all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182371ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearSVC\": LinearSVC(class_weight=\"balanced\", max_iter=4000, random_state=42),\n",
    "    \"SGDClassifier_hinge\": SGDClassifier(loss=\"hinge\", class_weight=\"balanced\", max_iter=4000, random_state=42),\n",
    "    \"SGDClassifier_log\": SGDClassifier(loss=\"log_loss\", class_weight=\"balanced\", max_iter=4000, random_state=42),\n",
    "    \"DecisionForest\": RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=None, \n",
    "        min_samples_split=5, \n",
    "        class_weight=\"balanced\", \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": xgb.XGBClassifier(\n",
    "        use_label_encoder=False, \n",
    "        eval_metric=\"logloss\", \n",
    "        n_estimators=200, \n",
    "        scale_pos_weight=len(y[y==0])/len(y[y==1]), \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(\n",
    "        n_estimators=200, \n",
    "        class_weight=\"balanced\", \n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"NeuralNetwork\": MLPClassifier(\n",
    "        hidden_layer_sizes=(100,), \n",
    "        activation='relu', \n",
    "        solver='adam', \n",
    "        max_iter=500, \n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3400cb3",
   "metadata": {},
   "source": [
    "## 4. Train and evaluate all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041339e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAINING: LinearSVC ===\n",
      "Accuracy: 0.470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.55      0.62      1982\n",
      "           1       0.11      0.18      0.13       573\n",
      "\n",
      "    accuracy                           0.47      2555\n",
      "   macro avg       0.40      0.37      0.38      2555\n",
      "weighted avg       0.57      0.47      0.51      2555\n",
      "\n",
      "\n",
      "=== TRAINING: SGDClassifier_hinge ===\n",
      "Accuracy: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62      1982\n",
      "           1       0.22      0.49      0.31       573\n",
      "\n",
      "    accuracy                           0.51      2555\n",
      "   macro avg       0.50      0.50      0.46      2555\n",
      "weighted avg       0.65      0.51      0.55      2555\n",
      "\n",
      "\n",
      "=== TRAINING: SGDClassifier_log ===\n",
      "Accuracy: 0.522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      1982\n",
      "           1       0.12      0.17      0.14       573\n",
      "\n",
      "    accuracy                           0.52      2555\n",
      "   macro avg       0.42      0.40      0.40      2555\n",
      "weighted avg       0.59      0.52      0.55      2555\n",
      "\n",
      "\n",
      "=== TRAINING: DecisionForest ===\n",
      "Accuracy: 0.853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1982\n",
      "           1       0.78      0.48      0.59       573\n",
      "\n",
      "    accuracy                           0.85      2555\n",
      "   macro avg       0.82      0.72      0.75      2555\n",
      "weighted avg       0.85      0.85      0.84      2555\n",
      "\n",
      "\n",
      "=== TRAINING: NeuralNetwork ===\n",
      "Accuracy: 0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1982\n",
      "           1       0.68      0.50      0.57       573\n",
      "\n",
      "    accuracy                           0.83      2555\n",
      "   macro avg       0.77      0.72      0.74      2555\n",
      "weighted avg       0.82      0.83      0.82      2555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n=== TRAINING: {name} ===\")\n",
    "    \n",
    "    # Build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "    \n",
    "    # Fit model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_class0\": report[\"0\"][\"f1-score\"],\n",
    "        \"f1_class1\": report[\"1\"][\"f1-score\"],\n",
    "        \"f1_macro\": report[\"macro avg\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545dee61",
   "metadata": {},
   "source": [
    "## 5. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfe7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL COMPARISON ===\n",
      "                 model  accuracy  f1_class0  f1_class1  f1_macro\n",
      "0       DecisionForest  0.853229   0.910394   0.594595  0.752494\n",
      "1        NeuralNetwork  0.834051   0.896937   0.574297  0.735617\n",
      "2  SGDClassifier_hinge  0.507632   0.618094   0.307269  0.462681\n",
      "3    SGDClassifier_log  0.521722   0.668655   0.140647  0.404651\n",
      "4            LinearSVC  0.470059   0.618161   0.134271  0.376216\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results).sort_values(by=\"f1_macro\", ascending=False)\n",
    "df_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164a2fd",
   "metadata": {},
   "source": [
    "## 6. SAVE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df95d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: DecisionForest -> best_model_all_models.pkl\n"
     ]
    }
   ],
   "source": [
    "best_model_name = df_results.loc[0, \"model\"]\n",
    "best_model_pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", models[best_model_name])\n",
    "])\n",
    "\n",
    "# Fit best model on full training set\n",
    "best_model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(best_model_pipeline, \"best_model_all_models.pkl\")\n",
    "print(f\"Saved best model: {best_model_name} -> best_model_all_models.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
